{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine learning for computational materials science and chemistry with MALA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What is MALA?\n",
    "\n",
    "A short summary about MALA and how it works is given in `mala_background.pdf`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up MALA\n",
    "\n",
    "For this tutorial, a Google Collab enviroment will be provided that includes all necessary packages. Generally, MALA is an open source framework that can be obtained [here](https://github.com/mala-project/mala). Detailled (installation) instructions can be found [here](https://mala-project.github.io/mala/).\n",
    "\n",
    "A few examples at the end of the notebook tackle advanced applications. The necessary backends are, for the ease of installation, not bundled with the Google Collab environment. Interested readers may install them themselves on their machines, for in presence workshops, they will be demonstrated by the host, as are sosme aspects of data generation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the modules\n",
    "\n",
    "These modules will be necessary for the tutorials discussed here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# MALA itself.\n",
    "\n",
    "import mala\n",
    "\n",
    "# We would like to visualize simple plots.\n",
    "# The font size can sometimes be a bit small for Jupyter Notebooks.\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'size'   : 22}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# For the data paths.\n",
    "from os.path import join as pj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data I: Performing simulations (presentation only)\n",
    "\n",
    "Data is the backbone of each ML application. For MALA, this includes target data (some electronic structure quantity to be learned, usually the local density of states, LDOS) and some descriptor data (a vectorial field that encodes the atomic density at each point in space, usually via so called bispectrum components).\n",
    "\n",
    "MALA data generation can be performed with the Quantum ESPRESSO package. Some changes to this open source package were necessary to enable the correct sampling of the LDOS. The current development branch of Quantum ESPRESSO includes those - beginning with Quantum ESPRESSO version 7.2 (to be released in ~June 2023) users can simply download the latest QE version and perform data generation.\n",
    "\n",
    "Data generation is two-fold: First, one creates a set of atomic position via a regular DFT-MD simulation at the conditions of interest. This can be done with any suitable code, such as VASP, QE, etc. Secondly, one performs DFT simulations to access the LDOS.\n",
    "\n",
    "The test system for our investigation here will be a simply beryllium system at room temperature consisting of 2 beryllium atoms. Atomic configurations have been sampled beforehand. We will start with the DFT simulation. Note: For actual data generation, the simulation output needs to be saved (usually as \".out\" file) and is of course done on HPC infrastructure."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MALA data generation thus comes down to a simply DFT + Postprocessing calculation. There is one drawback though: The LDOS has to be sampled with a very high fidelity in the k-space (phase space, i.e., how the Fourier components of the basis set are sampled). The fidelity of the MALA calculation has to be higher then for standard DFT calculations, which has to be kept in mind. A good way to visualize the problem is through the density of states (LDOS integrated on real space grid) which shows unphysical oscillations for low fidelity calculations. These oscillations vanish as one moves to higher fidelity calculations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![kpoint_comparison](./figures/DOSwdifferentdeltasandks.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After we have performed the actual simulation, we are halfway done. We now have simulation outputs, both the DFT output as well as the LDOS. From this we need to do two things:\n",
    "\n",
    "1. We need to convert the LDOS into a format we actually want to work with. Cube files are unnecessarily huge, complicated both disk usage as well as speed.\n",
    "2. We need to calculate the atomic density descriptors from the atomic positions.\n",
    "\n",
    "So it's finally time to fire up MALA."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The MALA interface (hands-on)\n",
    "\n",
    "Within extended ML frameworks, a big problem is reproducibility. Models often depend on a lot of so called hyperparameters, that characterize model behavior. This may include, but in no way be limited to, neural network layer sizes and number, training procedures, description of data specifics (e.g.: how is the local density of states sampled?), etc.\n",
    "There is a number of ways to efficiently handle this problem. A lot of frameworks rely on command line arguments to deal with this, i.e., the user provides a, potentially extensive, list of command line arguments upon runtime. Another good way to handle all this is the usage of input files. This is consistent with the way standard computational science simulation codes work.\n",
    "An obvious downside to this is that one has to have a framework at hand to prepare these input files.\n",
    "\n",
    "MALA follows a route sort of in between the two approaches. The central quantity is the `Parameters()` object. It holds ALL (hyper)parameters one could use in the course of a MALA run. It is structured by the subtasks of MALA."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<mala.common.parameters.ParametersHyperparameterOptimization at 0x7f5c63aac760>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = mala.Parameters()\n",
    "\n",
    "# All parameters related to how data is handled in general.\n",
    "parameters.data\n",
    "\n",
    "# \"Targets\" always refers to the quantity being learned.\n",
    "parameters.targets\n",
    "\n",
    "# \"Descriptors\" always refers to the quantity from which we learn.\n",
    "parameters.descriptors\n",
    "\n",
    "# \"Data generation\" refers to useful routines for creating training data.\n",
    "# These routines are mostly experimental at the moment and will not be discussed here in detail\n",
    "parameters.datageneration\n",
    "\n",
    "# \"Network\" refers to everything related to neural network creation and training.\n",
    "# In the future, support for more models is planned, and this collection of parameters\n",
    "# will be updated to reflect this.\n",
    "parameters.network\n",
    "\n",
    "# \"Hyperparameters\" means hyperparameter optimization. This is the process of finding the optimal\n",
    "# hyperparameters for MALA model training, and we will come back to this process later.\n",
    "parameters.hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Individual parameter objects can be printed to see what's hidden inside. This also works on the main object as well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshot_directories_list: []\n",
      "data_splitting_type: by_snapshot\n",
      "input_rescaling_type: None\n",
      "output_rescaling_type: None\n",
      "use_lazy_loading: False\n",
      "use_clustering : False\n",
      "number_of_clusters: 40\n",
      "train_ratio    : 0.1\n",
      "sample_ratio   : 0.5\n",
      "use_fast_tensor_data_set: False\n",
      "shuffling_seed : None\n"
     ]
    }
   ],
   "source": [
    "parameters.data.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, there are some high-level parameters one needs when performing ML at scale."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whether or not to use a GPU for model training and inference.\n",
    "parameters.use_gpu\n",
    "\n",
    "# Whether or not to use MPI parallel CPU inference (no training supported).\n",
    "# This option is either for pre-processing or production runs of trained models.\n",
    "# More on that later.\n",
    "parameters.use_mpi\n",
    "\n",
    "# Manual seeds can be used to fix the Pseudo RNG to re-create models with the exact\n",
    "# same model weights.\n",
    "parameters.manual_seed\n",
    "\n",
    "# A comment may be useful to distinguish between sets of parameters.\n",
    "parameters.comment\n",
    "\n",
    "# This is useful for adjusting the output level of MALA.\n",
    "parameters.verbosity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All of this does not explain how MALA handles reproducibility. Write hundreds of lines of parameter statement in each python script is not exactly maintainable.\n",
    "Therefore MALA provides a .json interface."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "parameters.save(\"mala_parameters_01.json\")\n",
    "new_parameters = mala.Parameters.load_from_file(\"mala_parameters_01.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Have a look at the .json file that was just created. You will see that it is structured in the same ways as the python object, allowing fast access. You will see some parameters that are not dicussed here since they exceed the scope of this tutorial. For a first excercise, try to modify parameters both in python and in json and see whether loading will recover those changes. The comment and manual seed are good first examples for this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Set a comment\n",
    "parameters.comment = \"My first parameters.\"\n",
    "\n",
    "# Save.\n",
    "parameters.save(\"mala_parameters_01.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---     All parameter MALA needs to perform its various tasks. ---\n",
      "comment        : My first parameters.\n",
      "manual_seed    : None\n",
      "use_gpu        : False\n",
      "device         : cpu\n",
      "use_horovod    : False\n",
      "use_mpi        : False\n",
      "verbosity      : 1\n",
      "openpmd_configuration: {}\n",
      "openpmd_granularity: 1\n",
      "---     Parameters necessary for constructing a neural network. ---\n",
      "\tnn_type        : feed-forward\n",
      "\tlayer_sizes    : [10, 10, 10]\n",
      "\tlayer_activations: ['Sigmoid']\n",
      "\tloss_function_type: mse\n",
      "\tnum_hidden_layers: 1\n",
      "\tno_hidden_state: False\n",
      "\tbidirection    : False\n",
      "\tdropout        : 0.1\n",
      "\tnum_heads      : 10\n",
      "---     Parameters necessary for calculating/parsing input descriptors. ---\n",
      "\tdescriptor_type: Bispectrum\n",
      "\tlammps_compute_file: \n",
      "\tdescriptors_contain_xyz: True\n",
      "\tuse_z_splitting: True\n",
      "\tnumber_y_planes: 0\n",
      "\tbispectrum_twojmax: 10\n",
      "\trcutfac        : 4.67637\n",
      "\tatomic_density_cutoff: 4.67637\n",
      "\tsnap_switchflag: 1\n",
      "\tuse_atomic_density_energy_formula: False\n",
      "\tatomic_density_sigma: None\n",
      "---     Parameters necessary for calculating/parsing output quantites. ---\n",
      "\ttarget_type    : LDOS\n",
      "\tldos_gridsize  : 0\n",
      "\tldos_gridspacing_ev: 0\n",
      "\tldos_gridoffset_ev: 0\n",
      "\trestrict_targets: zero_out_negative\n",
      "\tpseudopotential_path: None\n",
      "\trdf_parameters : {'number_of_bins': 500, 'rMax': 'mic'}\n",
      "\ttpcf_parameters: {'number_of_bins': 20, 'rMax': 'mic'}\n",
      "\tssf_parameters : {'number_of_bins': 100, 'kMax': 12.0}\n",
      "---     Parameters necessary for loading and preprocessing data. ---\n",
      "\tsnapshot_directories_list: []\n",
      "\tdata_splitting_type: by_snapshot\n",
      "\tinput_rescaling_type: None\n",
      "\toutput_rescaling_type: None\n",
      "\tuse_lazy_loading: False\n",
      "\tuse_clustering : False\n",
      "\tnumber_of_clusters: 40\n",
      "\ttrain_ratio    : 0.1\n",
      "\tsample_ratio   : 0.5\n",
      "\tuse_fast_tensor_data_set: False\n",
      "\tshuffling_seed : None\n",
      "---     Parameters needed for network runs (train, test or inference). ---\n",
      "\ttrainingtype   : SGD\n",
      "\tlearning_rate  : 0.5\n",
      "\tmax_number_epochs: 100\n",
      "\tverbosity      : True\n",
      "\tmini_batch_size: 10\n",
      "\tweight_decay   : 0\n",
      "\tearly_stopping_epochs: 0\n",
      "\tearly_stopping_threshold: 0\n",
      "\tlearning_rate_scheduler: None\n",
      "\tlearning_rate_decay: 0.1\n",
      "\tlearning_rate_patience: 0\n",
      "\tuse_compression: False\n",
      "\tnum_workers    : 0\n",
      "\tuse_shuffling_for_samplers: True\n",
      "\tcheckpoints_each_epoch: 0\n",
      "\tcheckpoint_name: checkpoint_mala\n",
      "\tvisualisation  : 0\n",
      "\tvisualisation_dir: ./mala_logging\n",
      "\tvisualisation_dir_append_date: True\n",
      "\tduring_training_metric: ldos\n",
      "\tafter_before_training_metric: ldos\n",
      "\tinference_data_grid: [0, 0, 0]\n",
      "\tuse_mixed_precision: False\n",
      "\tuse_graphs     : False\n",
      "\ttraining_report_frequency: 1000\n",
      "\tprofiler_range : [1000, 2000]\n",
      "---     Hyperparameter optimization parameters. ---\n",
      "\tdirection      : minimize\n",
      "\tn_trials       : 100\n",
      "\thyper_opt_method: optuna\n",
      "\tcheckpoints_each_trial: 0\n",
      "\tcheckpoint_name: checkpoint_mala_ho\n",
      "\tstudy_name     : None\n",
      "\trdb_storage    : None\n",
      "\trdb_storage_heartbeat: None\n",
      "\tnumber_training_per_trial: 1\n",
      "\ttrial_ensemble_evaluation: mean\n",
      "\tuse_multivariate: True\n",
      "\tnaswot_pruner_cutoff: 0\n",
      "\tpruner         : None\n",
      "\tnaswot_pruner_batch_size: 0\n",
      "\tnumber_bad_trials_before_stopping: None\n",
      "\tsqlite_timeout : 600\n",
      "\tacsd_points    : 100\n",
      "---     All parameters to help with data generation. ---\n",
      "\ttrajectory_analysis_denoising_width: 100\n",
      "\ttrajectory_analysis_below_average_counter: 50\n",
      "\ttrajectory_analysis_estimated_equilibrium: 0.1\n",
      "\tlocal_psp_path : None\n",
      "\tlocal_psp_name : None\n",
      "\tofdft_timestep : 0\n",
      "\tofdft_number_of_timesteps: 0\n",
      "\tofdft_temperature: 0\n",
      "\tofdft_kedf     : WT\n",
      "\tofdft_friction : 0.1\n"
     ]
    }
   ],
   "source": [
    "# Edit something in the file (e.g. the manual_seed) and reload.\n",
    "parameters = mala.Parameters.load_from_file(\"mala_parameters_01.json\")\n",
    "parameters.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For extended experiments, it is very useful to operate with such input files and only use the in-python parameter editing when absolutely necessary. Further, concluded experiments can be saved in this way for future reference.\n",
    "In the following, we will use a combination of both approaches for the sake of transparency."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data II: Data preprocessing (presentation-only)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now start using MALA to prepare our data. MALA directly takes in calculation outputs and transforms it into formats with which we can easily work.\n",
    "First, we have to decide which descriptors to calculate and how to correctly process the LDOS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "parameters = mala.Parameters()\n",
    "\n",
    "# These values we will take for granted now. In the hyperparameter section we will find out\n",
    "# how they are determined.\n",
    "parameters.descriptors.descriptor_type = \"Bispectrum\"\n",
    "parameters.descriptors.bispectrum_twojmax = 10\n",
    "parameters.descriptors.bispectrum_cutoff = 4.67637\n",
    "parameters.descriptors.descriptors_contain_xyz = True\n",
    "\n",
    "# These values need to correspond to the ones used in the DFT simulation.\n",
    "parameters.targets.target_type = \"LDOS\"\n",
    "parameters.targets.ldos_gridsize = 11\n",
    "parameters.targets.ldos_gridspacing_ev = 2.5\n",
    "parameters.targets.ldos_gridoffset_ev = -5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can use the `DataConverter` class to convert simulation outputs. File format labels follow the ASE package wherever possible!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabling z-splitting for preprocessing.\n",
      "Calculating descriptors from ./data_generation/dft.out\n"
     ]
    }
   ],
   "source": [
    "data_converter = mala.DataConverter(parameters)\n",
    "data_converter.add_snapshot(descriptor_input_type=\"espresso-out\",\n",
    "                            descriptor_input_path=\"./data_generation/dft.out\",\n",
    "                            target_input_type=\".cube\",\n",
    "                            target_input_path=\"./data_generation/tmp.pp0*Be_ldos.cube\")\n",
    "data_converter.convert_snapshots(\"./data_generation/\", naming_scheme=\"Be_snapshot*.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example we will use the [MALA test data set](https://github.com/mala-project/test-data), which contains 4 atomic configurations, including simulation output, bispectrum components and LDOS - i.e., this preprocessing has already been done for all of them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_path = \"/home/fiedlerl/data/mala_data_repo/Be2\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizing and reproducing output data (hands-on)\n",
    "\n",
    "Before we train a model, it is a good idea to think about which metric is important, i.e., how do we test if a model is good?\n",
    "\n",
    "In essence, the advantage of MALA is the access to multiple observables. Two easily accesible metrics are the density of states (DOS) and the band energy. We will now learn how to calculate them from the LDOS (the actual DFT LDOS in this case) so we can do the same after model training to test our models.\n",
    "\n",
    "For this, we first have to make sure the correct LDOS parameters are used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters.targets.target_type = \"LDOS\"\n",
    "parameters.targets.ldos_gridsize = 11\n",
    "parameters.targets.ldos_gridspacing_ev = 2.5\n",
    "parameters.targets.ldos_gridoffset_ev = -5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can create an LDOS calculator and directly populate it with the LDOS data from the data set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldos_calculator = mala.LDOS.from_numpy_file(parameters, pj(data_path, \"Be_snapshot0.out.npy\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Afterwards, we have to read in some additional information from the simulation data (size of the real space grid, temperature, etc.)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldos_calculator.read_additional_calculation_data(pj(data_path, \"Be_snapshot0.out\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can access the DOS and the band energy as properties of the calculator object."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(ldos_calculator.energy_grid, ldos_calculator.density_of_states)\n",
    "\n",
    "print(ldos_calculator.band_energy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training a model (hands-on)\n",
    "\n",
    "Finally, we can train a neural network based model for the electronic structure. First, let us review which parameters we need for this. In the following we will slowly adapt the parameters until we get a good model out of it.\n",
    "\n",
    "Since we want to learn about the inner workings of MALA, we want full output. We will also fix the manual seed, so that all the models are comparable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "parameters = mala.Parameters()\n",
    "parameters.verbosity = 2\n",
    "parameters.manual_seed = 2023"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since MALA provides quite a few reasonable default values, in the simplest case the only thing we have to decide upon is the data we want to learn on and the architecture of the neural network.\n",
    "\n",
    "For each training we have to specify training (`\"tr\"`) and validation (`\"va\"`) snapshots. The former are used to actually tune the network weights, the latter monitor model performance during training. They will become very relevant as we optimize the training process.\n",
    "\n",
    "Deciding on the layer sizes is usually done AFTER the data is loaded, since the first and last layer need to match up with the data provided."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data rescaling will be performed.\n",
      "No data rescaling will be performed.\n",
      "Checking the snapshots and your inputs for consistency.\n",
      "Checking descriptor file  Be_snapshot0.in.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "Checking targets file  Be_snapshot0.out.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "Checking descriptor file  Be_snapshot1.in.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "Checking targets file  Be_snapshot1.out.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "Consistency check successful.\n",
      "Initializing the data scalers.\n",
      "Input scaler parametrized.\n",
      "Output scaler parametrized.\n",
      "Data scalers initialized.\n",
      "Build datasets.\n",
      "Build dataset: Done.\n"
     ]
    }
   ],
   "source": [
    "data_handler = mala.DataHandler(parameters)\n",
    "data_handler.add_snapshot(\"Be_snapshot0.in.npy\", data_path,\n",
    "                          \"Be_snapshot0.out.npy\", data_path, \"tr\")\n",
    "data_handler.add_snapshot(\"Be_snapshot1.in.npy\", data_path,\n",
    "                          \"Be_snapshot1.out.npy\", data_path, \"va\")\n",
    "\n",
    "# This already loads data into RAM!\n",
    "data_handler.prepare_data()\n",
    "parameters.network.layer_sizes = [data_handler.input_dimension,\n",
    "                                  100,\n",
    "                                  data_handler.output_dimension]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can actually train a network."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Guess - validation data loss:  0.23660719517299106\n",
      "Epoch 0: validation data loss: 2.0642450877598352e-05, training data loss: 0.0010316168240138463\n",
      "Time for epoch[s]: 14.075532674789429\n",
      "Epoch 1: validation data loss: 8.426698190825327e-06, training data loss: 9.5022799713271e-06\n",
      "Time for epoch[s]: 0.5715315341949463\n",
      "Epoch 2: validation data loss: 6.573324224778584e-06, training data loss: 4.276818728872708e-06\n",
      "Time for epoch[s]: 0.49625110626220703\n",
      "Epoch 3: validation data loss: 6.066970527172088e-06, training data loss: 3.2637411994593483e-06\n",
      "Time for epoch[s]: 0.5719480514526367\n",
      "Epoch 4: validation data loss: 5.8819215212549484e-06, training data loss: 2.9526403439896447e-06\n",
      "Time for epoch[s]: 0.614145040512085\n",
      "Epoch 5: validation data loss: 5.756421280758722e-06, training data loss: 2.780921491129058e-06\n",
      "Time for epoch[s]: 0.8275718688964844\n",
      "Epoch 6: validation data loss: 5.729225065026964e-06, training data loss: 2.724048016326768e-06\n",
      "Time for epoch[s]: 0.9969642162322998\n",
      "Epoch 7: validation data loss: 5.697706980364663e-06, training data loss: 2.702274758900915e-06\n",
      "Time for epoch[s]: 0.8270742893218994\n",
      "Epoch 8: validation data loss: 5.712806646312986e-06, training data loss: 2.691476472786495e-06\n",
      "Time for epoch[s]: 0.7120273113250732\n",
      "Epoch 9: validation data loss: 5.707444357020515e-06, training data loss: 2.685247255223138e-06\n",
      "Time for epoch[s]: 0.7106037139892578\n",
      "Epoch 10: validation data loss: 5.702229482786996e-06, training data loss: 2.682395013315337e-06\n",
      "Time for epoch[s]: 0.6155221462249756\n",
      "Epoch 11: validation data loss: 5.692719348839351e-06, training data loss: 2.6807026671511785e-06\n",
      "Time for epoch[s]: 0.8146119117736816\n",
      "Epoch 12: validation data loss: 5.695252014057977e-06, training data loss: 2.679776932512011e-06\n",
      "Time for epoch[s]: 0.6083807945251465\n",
      "Epoch 13: validation data loss: 5.691708730799811e-06, training data loss: 2.6787942541497095e-06\n",
      "Time for epoch[s]: 0.5773789882659912\n",
      "Epoch 14: validation data loss: 5.692836429391588e-06, training data loss: 2.6785630200590405e-06\n",
      "Time for epoch[s]: 0.7173018455505371\n",
      "Epoch 15: validation data loss: 5.673026932137353e-06, training data loss: 2.677937437381063e-06\n",
      "Time for epoch[s]: 0.789555549621582\n",
      "Epoch 16: validation data loss: 5.694691091775894e-06, training data loss: 2.678379150373595e-06\n",
      "Time for epoch[s]: 0.6404266357421875\n",
      "Epoch 17: validation data loss: 5.685808935335704e-06, training data loss: 2.6772831167493547e-06\n",
      "Time for epoch[s]: 0.5561385154724121\n",
      "Epoch 18: validation data loss: 5.695537797042301e-06, training data loss: 2.677000526871e-06\n",
      "Time for epoch[s]: 0.7231574058532715\n",
      "Epoch 19: validation data loss: 5.695699048893792e-06, training data loss: 2.6767663657665252e-06\n",
      "Time for epoch[s]: 0.774376630783081\n",
      "Epoch 20: validation data loss: 5.697107740810939e-06, training data loss: 2.6764550379344395e-06\n",
      "Time for epoch[s]: 0.6875059604644775\n",
      "Epoch 21: validation data loss: 5.683457744973047e-06, training data loss: 2.6765835604497364e-06\n",
      "Time for epoch[s]: 0.8308591842651367\n",
      "Epoch 22: validation data loss: 5.688743931906564e-06, training data loss: 2.675719027008329e-06\n",
      "Time for epoch[s]: 0.7643272876739502\n",
      "Epoch 23: validation data loss: 5.687439548117774e-06, training data loss: 2.6755500584840774e-06\n",
      "Time for epoch[s]: 0.9397306442260742\n",
      "Epoch 24: validation data loss: 5.696567041533334e-06, training data loss: 2.6751743363482613e-06\n",
      "Time for epoch[s]: 1.0406899452209473\n",
      "Epoch 25: validation data loss: 5.686759948730469e-06, training data loss: 2.674911969474384e-06\n",
      "Time for epoch[s]: 0.6029198169708252\n",
      "Epoch 26: validation data loss: 5.6885060455117905e-06, training data loss: 2.6745322559561047e-06\n",
      "Time for epoch[s]: 0.583899974822998\n",
      "Epoch 27: validation data loss: 5.679631871836526e-06, training data loss: 2.6747254388672967e-06\n",
      "Time for epoch[s]: 0.9348618984222412\n",
      "Epoch 28: validation data loss: 5.678408380065645e-06, training data loss: 2.674342000058719e-06\n",
      "Time for epoch[s]: 0.5834403038024902\n",
      "Epoch 29: validation data loss: 5.6765563786029815e-06, training data loss: 2.6734617671796254e-06\n",
      "Time for epoch[s]: 0.523076057434082\n",
      "Epoch 30: validation data loss: 5.689655031476702e-06, training data loss: 2.6729524667773927e-06\n",
      "Time for epoch[s]: 0.6305310726165771\n",
      "Epoch 31: validation data loss: 5.668357546840395e-06, training data loss: 2.67244635948113e-06\n",
      "Time for epoch[s]: 0.8350734710693359\n",
      "Epoch 32: validation data loss: 5.673676729202271e-06, training data loss: 2.671939453908375e-06\n",
      "Time for epoch[s]: 0.7913932800292969\n",
      "Epoch 33: validation data loss: 5.662577492850168e-06, training data loss: 2.6723119829382214e-06\n",
      "Time for epoch[s]: 0.682532787322998\n",
      "Epoch 34: validation data loss: 5.666138870375497e-06, training data loss: 2.670639327594212e-06\n",
      "Time for epoch[s]: 0.6397969722747803\n",
      "Epoch 35: validation data loss: 5.6451053491660525e-06, training data loss: 2.669292901243482e-06\n",
      "Time for epoch[s]: 0.6119339466094971\n",
      "Epoch 36: validation data loss: 5.596482860190528e-06, training data loss: 2.6646525199924197e-06\n",
      "Time for epoch[s]: 0.5647501945495605\n",
      "Epoch 37: validation data loss: 5.599578044244221e-06, training data loss: 2.6184325771672383e-06\n",
      "Time for epoch[s]: 0.5498390197753906\n",
      "Epoch 38: validation data loss: 5.596215171473367e-06, training data loss: 2.6153421827725e-06\n",
      "Time for epoch[s]: 0.5725610256195068\n",
      "Epoch 39: validation data loss: 5.597453032221113e-06, training data loss: 2.6145593396254948e-06\n",
      "Time for epoch[s]: 0.4898519515991211\n",
      "Epoch 40: validation data loss: 5.600179412535258e-06, training data loss: 2.613751749907221e-06\n",
      "Time for epoch[s]: 0.589958906173706\n",
      "Epoch 41: validation data loss: 5.597214613642011e-06, training data loss: 2.6128121784755164e-06\n",
      "Time for epoch[s]: 0.7074122428894043\n",
      "Epoch 42: validation data loss: 5.597128399780818e-06, training data loss: 2.6135175888027466e-06\n",
      "Time for epoch[s]: 0.6498312950134277\n",
      "Epoch 43: validation data loss: 5.5973817195211136e-06, training data loss: 2.612104107226644e-06\n",
      "Time for epoch[s]: 0.49660253524780273\n",
      "Epoch 44: validation data loss: 5.596153438091278e-06, training data loss: 2.6118976197072436e-06\n",
      "Time for epoch[s]: 0.6109602451324463\n",
      "Epoch 45: validation data loss: 5.5981714810643874e-06, training data loss: 2.6113949716091155e-06\n",
      "Time for epoch[s]: 0.5843162536621094\n",
      "Epoch 46: validation data loss: 5.596881466252463e-06, training data loss: 2.6079706315483367e-06\n",
      "Time for epoch[s]: 0.6611764430999756\n",
      "Epoch 47: validation data loss: 5.593972014529365e-06, training data loss: 2.60619047497e-06\n",
      "Time for epoch[s]: 0.7518255710601807\n",
      "Epoch 48: validation data loss: 5.599977714674813e-06, training data loss: 2.603631200534957e-06\n",
      "Time for epoch[s]: 0.6135280132293701\n",
      "Epoch 49: validation data loss: 5.5985237870897565e-06, training data loss: 2.6030471282345906e-06\n",
      "Time for epoch[s]: 0.535102128982544\n",
      "Epoch 50: validation data loss: 5.598042160272598e-06, training data loss: 2.6024886007819857e-06\n",
      "Time for epoch[s]: 0.915785551071167\n",
      "Epoch 51: validation data loss: 5.594375410250255e-06, training data loss: 2.6023324046816145e-06\n",
      "Time for epoch[s]: 0.9687020778656006\n",
      "Epoch 52: validation data loss: 5.595672343458448e-06, training data loss: 2.6014354079961777e-06\n",
      "Time for epoch[s]: 0.7520744800567627\n",
      "Epoch 53: validation data loss: 5.5941359273024966e-06, training data loss: 2.601393365434238e-06\n",
      "Time for epoch[s]: 0.8056824207305908\n",
      "Epoch 54: validation data loss: 5.59027014034135e-06, training data loss: 2.600994227187974e-06\n",
      "Time for epoch[s]: 0.5770814418792725\n",
      "Epoch 55: validation data loss: 5.588012614420482e-06, training data loss: 2.6007366499730518e-06\n",
      "Time for epoch[s]: 0.5289945602416992\n",
      "Epoch 56: validation data loss: 5.5851233857018605e-06, training data loss: 2.6008641081196923e-06\n",
      "Time for epoch[s]: 0.504213809967041\n",
      "Epoch 57: validation data loss: 5.582323563950402e-06, training data loss: 2.600413347993578e-06\n",
      "Time for epoch[s]: 0.5193929672241211\n",
      "Epoch 58: validation data loss: 5.578838820968356e-06, training data loss: 2.599148345845086e-06\n",
      "Time for epoch[s]: 0.5525875091552734\n",
      "Epoch 59: validation data loss: 5.572438240051269e-06, training data loss: 2.5972436581339156e-06\n",
      "Time for epoch[s]: 0.5304019451141357\n",
      "Epoch 60: validation data loss: 5.571066801037107e-06, training data loss: 2.5952979922294615e-06\n",
      "Time for epoch[s]: 0.610764741897583\n",
      "Epoch 61: validation data loss: 5.5686293968132565e-06, training data loss: 2.5935274149690357e-06\n",
      "Time for epoch[s]: 0.9232916831970215\n",
      "Epoch 62: validation data loss: 5.569770932197571e-06, training data loss: 2.5923800255571095e-06\n",
      "Time for epoch[s]: 0.6547732353210449\n",
      "Epoch 63: validation data loss: 5.569536771093096e-06, training data loss: 2.590401896408626e-06\n",
      "Time for epoch[s]: 0.5143871307373047\n",
      "Epoch 64: validation data loss: 5.5699955139841356e-06, training data loss: 2.587507079754557e-06\n",
      "Time for epoch[s]: 0.4905548095703125\n",
      "Epoch 65: validation data loss: 5.571945969547544e-06, training data loss: 2.585990886603083e-06\n",
      "Time for epoch[s]: 0.46637797355651855\n",
      "Epoch 66: validation data loss: 5.570605929408755e-06, training data loss: 2.5850747312818256e-06\n",
      "Time for epoch[s]: 0.6118371486663818\n",
      "Epoch 67: validation data loss: 5.5687097566468375e-06, training data loss: 2.5844089686870573e-06\n",
      "Time for epoch[s]: 0.7926161289215088\n",
      "Epoch 68: validation data loss: 5.5684234414781845e-06, training data loss: 2.583767952663558e-06\n",
      "Time for epoch[s]: 0.7259180545806885\n",
      "Epoch 69: validation data loss: 5.568031221628189e-06, training data loss: 2.583315862076623e-06\n",
      "Time for epoch[s]: 0.7184686660766602\n",
      "Epoch 70: validation data loss: 5.568735833678927e-06, training data loss: 2.5833770632743836e-06\n",
      "Time for epoch[s]: 0.6295461654663086\n",
      "Epoch 71: validation data loss: 5.564784897225244e-06, training data loss: 2.583258120076997e-06\n",
      "Time for epoch[s]: 0.5676460266113281\n",
      "Epoch 72: validation data loss: 5.56598390851702e-06, training data loss: 2.581950543182237e-06\n",
      "Time for epoch[s]: 0.5125396251678467\n",
      "Epoch 73: validation data loss: 5.565719945090158e-06, training data loss: 2.5817565619945525e-06\n",
      "Time for epoch[s]: 0.5333960056304932\n",
      "Epoch 74: validation data loss: 5.565832768167768e-06, training data loss: 2.581356625471796e-06\n",
      "Time for epoch[s]: 0.5480928421020508\n",
      "Epoch 75: validation data loss: 5.565087177923748e-06, training data loss: 2.580558881163597e-06\n",
      "Time for epoch[s]: 0.5401206016540527\n",
      "Epoch 76: validation data loss: 5.562589636870793e-06, training data loss: 2.5804849075419563e-06\n",
      "Time for epoch[s]: 0.5585849285125732\n",
      "Epoch 77: validation data loss: 5.565952509641647e-06, training data loss: 2.5803497327225548e-06\n",
      "Time for epoch[s]: 0.7106566429138184\n",
      "Epoch 78: validation data loss: 5.563034010784967e-06, training data loss: 2.580023503729275e-06\n",
      "Time for epoch[s]: 0.5654194355010986\n",
      "Epoch 79: validation data loss: 5.562925445181983e-06, training data loss: 2.579802115048681e-06\n",
      "Time for epoch[s]: 0.5879652500152588\n",
      "Epoch 80: validation data loss: 5.562736519745418e-06, training data loss: 2.5802270642348698e-06\n",
      "Time for epoch[s]: 0.6572055816650391\n",
      "Epoch 81: validation data loss: 5.562308643545423e-06, training data loss: 2.579363062977791e-06\n",
      "Time for epoch[s]: 0.5458753108978271\n",
      "Epoch 82: validation data loss: 5.561845643179758e-06, training data loss: 2.5790315121412277e-06\n",
      "Time for epoch[s]: 0.5072858333587646\n",
      "Epoch 83: validation data loss: 5.563337888036455e-06, training data loss: 2.578034996986389e-06\n",
      "Time for epoch[s]: 0.5083973407745361\n",
      "Epoch 84: validation data loss: 5.56429528764316e-06, training data loss: 2.5765475417886463e-06\n",
      "Time for epoch[s]: 0.5179479122161865\n",
      "Epoch 85: validation data loss: 5.562386874641691e-06, training data loss: 2.5758596935442517e-06\n",
      "Time for epoch[s]: 0.4535949230194092\n",
      "Epoch 86: validation data loss: 5.56017884186336e-06, training data loss: 2.5747971875326973e-06\n",
      "Time for epoch[s]: 0.5580353736877441\n",
      "Epoch 87: validation data loss: 5.5602288671902245e-06, training data loss: 2.575417182275227e-06\n",
      "Time for epoch[s]: 0.5249660015106201\n",
      "Epoch 88: validation data loss: 5.557117185422352e-06, training data loss: 2.574138343334198e-06\n",
      "Time for epoch[s]: 0.47477126121520996\n",
      "Epoch 89: validation data loss: 5.5592177169663566e-06, training data loss: 2.5747716426849364e-06\n",
      "Time for epoch[s]: 0.5890536308288574\n",
      "Epoch 90: validation data loss: 5.56168332695961e-06, training data loss: 2.5739302592618126e-06\n",
      "Time for epoch[s]: 0.5673470497131348\n",
      "Epoch 91: validation data loss: 5.556233759437289e-06, training data loss: 2.574151914034571e-06\n",
      "Time for epoch[s]: 0.5707414150238037\n",
      "Epoch 92: validation data loss: 5.5582448840141295e-06, training data loss: 2.5735893951995033e-06\n",
      "Time for epoch[s]: 0.46752429008483887\n",
      "Epoch 93: validation data loss: 5.5569506117275784e-06, training data loss: 2.573606957282339e-06\n",
      "Time for epoch[s]: 0.48187875747680664\n",
      "Epoch 94: validation data loss: 5.556435457297734e-06, training data loss: 2.573434263467789e-06\n",
      "Time for epoch[s]: 0.566683292388916\n",
      "Epoch 95: validation data loss: 5.555758518832071e-06, training data loss: 2.573469919817788e-06\n",
      "Time for epoch[s]: 0.7254226207733154\n",
      "Epoch 96: validation data loss: 5.555643034832818e-06, training data loss: 2.572829702070781e-06\n",
      "Time for epoch[s]: 0.7218220233917236\n",
      "Epoch 97: validation data loss: 5.554889461823872e-06, training data loss: 2.572573721408844e-06\n",
      "Time for epoch[s]: 0.5735270977020264\n",
      "Epoch 98: validation data loss: 5.557044808353697e-06, training data loss: 2.5722972516502653e-06\n",
      "Time for epoch[s]: 0.5974586009979248\n",
      "Epoch 99: validation data loss: 5.555403019700731e-06, training data loss: 2.572127484849521e-06\n",
      "Time for epoch[s]: 0.7279651165008545\n",
      "Final validation data loss:  5.555403019700731e-06\n"
     ]
    }
   ],
   "source": [
    "network = mala.Network(parameters)\n",
    "trainer = mala.Trainer(parameters, network, data_handler)\n",
    "trainer.train_network()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Well, how was that? Do we have a good model now, can we predict the LDOS with this? That is not an easy question to answer from this output alone. First of all, we see loss values being printed, and those look all nice, but they are not trivially related to physical/chemical accuracy, which we are actually looking for.\n",
    "\n",
    "We can test this by using the `Tester` class. The class works similar to the Trainer class. We add data, push them through the model, and then use the results to perform calculations.\n",
    "\n",
    "We just have to make sure that the LDOS is correctly integrated by setting the appropriate parameters. Then we can add data to test. We should always test on data different from the one we trained on. Also, we now have to specify the corresponding calculation output, since we may need this for integration."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the snapshots and your inputs for consistency.\n",
      "Checking descriptor file  Be_snapshot2.in.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "Checking targets file  Be_snapshot2.out.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "Checking descriptor file  Be_snapshot3.in.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "Checking targets file  Be_snapshot3.out.npy at /home/fiedlerl/data/mala_data_repo/Be2\n",
      "DataHandler prepared for inference. No training possible with this setup. If this is not what you wanted, please revise the input script. Validation snapshots you may have entered willbe ignored.\n",
      "Consistency check successful.\n",
      "Build datasets.\n",
      "Build dataset: Done.\n"
     ]
    }
   ],
   "source": [
    "parameters.targets.ldos_gridsize = 11\n",
    "parameters.targets.ldos_gridspacing_ev = 2.5\n",
    "parameters.targets.ldos_gridoffset_ev = -5\n",
    "\n",
    "data_handler.clear_data()\n",
    "data_handler.add_snapshot(\"Be_snapshot2.in.npy\", data_path,\n",
    "                          \"Be_snapshot2.out.npy\", data_path, \"te\",\n",
    "                          calculation_output_file=pj(data_path, \"Be_snapshot2.out\"))\n",
    "data_handler.add_snapshot(\"Be_snapshot3.in.npy\", data_path,\n",
    "                          \"Be_snapshot3.out.npy\", data_path, \"te\",\n",
    "                          calculation_output_file=pj(data_path, \"Be_snapshot3.out\"))\n",
    "data_handler.prepare_data(reparametrize_scaler=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now comes the actual object with which to test. We simply tell it which observables to test for and off we go."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "tester = mala.Tester(parameters, network, data_handler, observables_to_test=[\"band_energy\"])\n",
    "results = tester.test_all_snapshots()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'band_energy': [-0.0352251206432328, -0.02902837244603873]}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}